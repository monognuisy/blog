---
title: Kalman Filter - 1 Dimensional
date: "2023-06-21"
description: "Localization 의 대표적 방법인 Kalman filter에 대해 알아보자."
tags: ["AI","Mathematics"]
categories: "AI - Bayesian Approach"
sidenotes: [
  {
    id: 1,
    content: "latent variable 이라고도 한다."
  },
]
---

import { Highlight, textHighlightBlue, textHighlightRed, Code } from "../../../src/utils/blogUtils.tsx";
import { Sidenote } from "../../../src/utils/blogUtils.tsx"
import { Link } from "gatsby";

## 배경

일단, 칼만 필터가 무엇인지 정확하게 알아보기 전에, 이것이 쓰인 대표적인 사건을 알아보자. 

바로 아폴로 미션이다.

아무것도 없는 우주 공간에서 현재 자신의 위치를 아는 것은 굉장히 중요하다. 이를 기반으로 목적지까지 도달하는 방법이 달라지기 때문이다. 심지어 우주선의 위치는 계속하여 바뀌고, 측정기의 성능이 완벽하지 않으므로 이는 더욱 어려워진다. 외력이 거의 없으므로 예측하기 쉽겠다고 생각하는 사람이 있을지도 모르니, 한 극단적인 예시를 들어보자. 

인류 역사상 가장 성공적인 실패라고 불리는 ‘아폴로 13 미션’은 달 탐사를 가던 도중, 산소 탱크가 폭파되어 탐사를 포기하고 지구로 복귀한 사건이다. 우주선의 동력과 내부 산소 등이 모두 부족한 극한 환경에서 대원들은 기적적으로 모두 무사 복귀하였다.

이 아폴로 13 미션에서는, 지구로 복귀하는 과정에서 그 어느때보다 현재 자신의 위치를 알아내는 기법인 localization이 중요했다. 만일 그 위치를 조금이라도 어긋나게 계산한다면 중력권을 벗어나서 영영 우주미아가 되거나 중력의 영향을 너무 세게 받아서 지면과 큰 충돌이 일어나 죽게 될지도 모르는 상황이었다.

심지어는 그 당시에 산소가 새고 있었기 때문에, 우주선은 수시로 랜덤하게 흔들렸고 이는 더욱 localization을 까다롭게 했다.

더욱이, 그 당시의 컴퓨터는 우리의 상상보다 훨씬 느렸고, 전력도 심각하게 부족하여, 정밀한 값을 얻기 위해 큰 비용의 계산을 시킬 수 없는 상황이었다.

그때 이들을 구원한 것은 바로 칼만 필터(Kalman Filter)였다. 이는 지금까지의 측정값을 기반으로 현재 위치를 추정하는 방법으로, 많이 측정할 수록 재귀적으로 정확도가 높아지는 경향이 있는 알고리즘이다. 또한, 기존의 알고리즘에 비해 매우 빠르고 값싸게 수행될 수 있어서 비단 아폴로 13 미션 뿐만 아닌, 다른 아폴로 미션에서도 유용하게 쓰였던 알고리즘이다.

결국, 조금 과장하자면 그 당시 칼만 필터가 없었다면 아마도 아폴로 13 미션은 인류 역사에 있어서 굉장히 끔찍한 참사로 남게 되었을지도 모른다. 그래서, NASA 측에서도 칼만 필터의 최초의 활용 사례로 아폴로 미션을 꼽고 있으며, 칼만 필터의 고안에 투자를 한 투자사도 이를 대대적으로 홍보하고 있다.

## 1차원 칼만 필터

localization 예시를 계속 생각해보자. $t$ 시점에 실제 나의 위치를 $x_t$ 라고 하고, 측정된 위치를 $y_t$ 라고 하자. 

이때, 실제 위치인 $x_t$는 <Sidenote id={1}>hidden</Sidenote> 이다. 즉, 우리는 측정된 위치 $y_t$만 알 수 있을 뿐이다.

여기서 다음과 같은 종속관계를 가정하자.

$$
\begin{cases}
x_{t + 1} &= \alpha x_{t} + \beta + \varepsilon_{x} \\
y_{t} &= \lambda x_t + \varepsilon_y 
\end{cases}
$$

단, 여기서 $\alpha, \beta \in \R$ 인 상수이고, $\varepsilon_x, \varepsilon_y$ 는 모두 평균이 $0$ 인 정규분포를 따른다. 또한, $x_0$ 도 가우시안이라고 가정한다.

당연히 다음 위치는 이전 위치와 밀접한 관계가 있고, 측정값은 실제 위치와 밀접한 관계가 있다고 생각하면 이 가정은 자연스럽다.

이러면, 다음과 같은 graphical model을 생각해볼 수 있다.

$$
\begin{CD}
  x_0 @>>> x_1 @>>> \cdots @>>> x_t @>>> \cdots @>>> x_T \\
  @VVV  @VVV  @.  @VVV  @.  @VVV \\
  y_0 @>>> y_1 @>>> \cdots @>>> y_t @>>> \cdots @>>> y_T 
\end{CD}
$$

즉, joint probability $p(x_0, \cdots, x_T, y_0 , \cdots, y_T)$ 는 다음과 같다.

$$
p(x_0)p(y_0 | x_0) p(x_1 | x_0)p(y_1 | x_1) \cdots p(x_{T} | x_{T-1}) p(y_T | x_T)
$$

여기서 우리의 목적은 기존의 측정값인 $y_0, \cdots, y_{T-1}$ 와 새로운 측정값 $y_T$ 를 이용하여 실제값인 $x_T$를 추정하는 것이다. 즉, 다음을 구하는 것이다.

$$
p(x_T | y_0, \cdots, y_T)
$$

이를 위해서는 $x_0 , \cdots, x_{T-1}$  의 총 $T$ 개의 변수를 marginalize 하고 $y_0, \cdots, y_T$ 를 conditioning 해야 한다. 무척이나 번거로운 작업이 아닐 수 없다. 하지만, 우리는 다음과 같은 사실을 안다!

1. gaussian을 marginalize 해도 gaussian!
2. gaussian을 conditioning 해도 gaussian!

즉, 결과물은 gaussian이므로 그것의 평균과 분산만 알면 되는 것이다.

### Option I - Closed form

또한, 다음을 알고 있으므로 

$$
\bm\mu_{1|2} = \bm\mu_1 + \Sigma_{12} \Sigma_{2}^{-1} ({\bf x}_2 - \bm\mu_2)
$$

$x_{T} | y_0, \cdots, y_T$ 의 평균은 다음과 같다.

$$
\mu_{x_T | y_0, \cdots, y_T} = \mu_{x_T} + \Sigma_{x_T, y_0, \cdots, y_T} \Sigma _{y_0, \cdots, y_T}^{-1} ((y_0, \cdots, y_T)^\top  - \bm\mu_{y_0, \cdots, y_T})
$$

와! 근데…

#### 🤔 문제점

물론 closed form이긴 한데… 조금 생각해보면 이 부분이 마음에 걸린다.

$$
\Sigma _{y_0, \cdots, y_T}^{-1}
$$

이 covariance matrix는 $\R^{(T+1) \times (T+1)}$ 으로, inverse는 rank의 세제곱에 비례하는 time complexity를 가지고 있으므로, 대략적으로 계산해도 다음과 같은 하한을 가진다.

$$
\Omega((T+1)^3)
$$

세제곱의 order를 가지는 알고리즘은 흔히 ‘**좋지 않다고**’ 여겨진다. 

심지어, 6~70년대의 컴퓨터로 이정도의 계산을 하려고 하면 정말 오래 걸릴 뿐더러, 아폴로 13 미션 당시의 급박한 상황에서는 섣불리 이러한 계산을 할 엄두가 나지 않았을 것이다.

결국 inverse가 가장 큰 overhead인데, 이를 최소화 하는 방법이 있을까? 그렇다. 없었다면, 아폴로 미션이 존재하지 못했을 것이다.

### Option II - Recursive update

한꺼번에 closed form을 구하려고 하지 말고, 앞서 가정한 종속관계에 따라 이를 재귀적으로 update해보자.

현재 시각 $T$ 대신, 임의의 시간 $t$를 가정하자.

앞으로, 혼동이 없을 때에는 편하게 다음과 같은 표기를 사용한다.

$$
{t+1 ~|~ t+1} := {x_{t+1} | y_0, \cdots, y_{t+1}}
$$

$$
t+1 , t+1 ~|~ t := x_{t+1}, y_{t+1} | y_{0} ,\cdots, y_t 
$$

#### Observation update: $\mu _{t+1 | t+1}$

먼저, 새로운 측정값 $y_{t + 1}$를 이용하여 update 하는 과정을 알아보자. 

conditional mean은 다음과 같다.

$$
\mu_{t+1 | t+1} = \mu_{t+1 | t} + \sigma_{t+1, t+1 | t} ~\sigma^{-2}_{y_{t+1} | t} ~(y_{t+1} - \mathbb{E}[y_{t+1} | t])
$$

이를 정리하기에 앞서, 이전에 overhead가 되었던 부분인 $\sigma_{y_{t+1} | t}$  부분을 살펴보면, 이는 1-dimensional이다. 따라서, $O(1)$ 에 inverse가 수행될 수 있다.

이것이 $t = 1 , \cdots, T$ 까지 수행하면 되므로, $O(T)$ 에 $\mu_{T | T}$ 를 구할 수 있다!

엄청난 발전이다. 하지만 아직 놀라긴 이르다. 위 식을 좀 더 정리하기 위해서 $\sigma_{t+1, t+1 | t}$ 와 $\sigma_{y_{t+1} | t}$ 를 정리하면 다음과 같다.

$$
\begin{align*}
\sigma^2_{y_{t+1} | t} &= \mathbb{E}[(\lambda x_{t+1} + \varepsilon_y)^2 | t] - \mathbb{E}[\lambda x_{t+1} + \varepsilon_y | t]^2 \\
&= \lambda ^2 \mathbb{E}[x_{t+1}^2 | t] + \lambda \mathbb{E}[x_{t+1}\varepsilon_y | t ] + \mathbb{E}[\varepsilon_y^2 | t] - \lambda^2 \mathbb{E}[x_{t+1} | t]^2 
\end{align*}
$$

여기서 $\varepsilon_y$ 는 $y_0 ,\cdots, y_t$ 에 대해 independent 하므로 $\mathbb{E}[\varepsilon _y | t] = \mathbb{E}[\varepsilon_y] = 0$ 이고,

$x_{t+1}$ 과도 independent 하므로, $\mathbb{E}[x_{t+1} \varepsilon_y | t] = \mathbb{E}[x_{t+1} | t]\mathbb{E}[ \varepsilon_y | t] = 0$ 이다.

또한, $\mathbb{E}[x_{t+1} ^2 | t] - \mathbb{E}[x_{t+1} | t]^2 = \sigma_{t+1 | t}^2$ 이므로, 식은 다음과 같다.

$$
\sigma_{y_{t+1} | t}^2 = \lambda^2 \sigma_{t+1 | t}^2 + \mathbb{E}[\varepsilon^2_y]
$$

$\sigma_{t+1, t+1 | t}$ 또한 계산해보면

$$
\begin{align*}
\sigma_{t+1, t+1 | t} &= \mathbb{E}[x_{t+1}(\lambda x_{t+1} + \varepsilon_y) | t] - \mathbb{E}[x_{t+1} | t]~\mathbb{E}[\lambda x_{t+1} + \varepsilon_y | t] \\
&= \lambda \mathbb{E}[x_{t+1} ^2 | t ] - \lambda\mathbb{E}[x_{t+1} | t]^2 \\
&= \lambda \sigma_{t+1 | t}^2
\end{align*}
$$

따라서, mean은 다음과 같다.

$$
\begin{align*}
\mu_{t+1 | t+1} &= \mu_{t+1 | t} + \frac{\lambda \sigma^2_{t+1 | t}}{\lambda^2 \sigma^2_{t+1 | t} + \mathbb{E}[\varepsilon^2_y ]} (y_{t+1} - \lambda \mu_{t+1 | t}) \\
&=\textcolor{crimson}{\frac{\mathbb{E}[\varepsilon_y^2]}{{\lambda^2 \sigma^2_{t+1 | t} + \mathbb{E}[\varepsilon^2_y ]}}} \mu_{t+1 | t} + \textcolor{cornflowerblue}{\frac{{\lambda^2 \sigma_{t+1 | t}^2 }}{{\lambda^2 \sigma^2_{t+1 | t} + \mathbb{E}[\varepsilon^2_y ]}} }\frac{y_{t+1}}{\lambda}

\end{align*}
$$

#### Observation update: $\sigma^2_{t+1 | t+1}$

이제는 분산을 구해보자. conditional covariance는 다음과 같이 구할 수 있다.

$$
\sigma^2_{t+1 | t+1} = \sigma^2_{t+1 | t} - \sigma_{t+1, t+1 | t} \sigma^{-2}_{y_{t+1} | t} \sigma_{t+1, t+1 | t}
$$

여기서 $\sigma_{t+1, t+1 | t} = \lambda \sigma_{t+1 | t}^2$ 와 $\sigma^{2}_{y_{t+1} | t} = \lambda^2 \sigma_{t+1 | t}^2 + \mathbb{E}[\varepsilon^2_y]$ 를 대입하면 식은 다음과 같다.

$$
\begin{align*}
\sigma^{2}_{t+1 | t+1} &= \sigma^2_{t+1 | t} - \cfrac{\lambda^2 \sigma_{t+1 | t}^4}{\lambda^2 \sigma_{t+1 | t}^2 + \mathbb{E}[\varepsilon^2_y]} \\
&= \textcolor{crimson}{\cfrac{ \mathbb{E}[\varepsilon^2_y]}{\lambda^2 \sigma_{t+1 | t}^2 + \mathbb{E}[\varepsilon^2_y]}} ~ \textcolor{cornflowerblue}{\sigma_{t+1 | t}^2}
\end{align*}
$$

여기서 붉게 표시된 부분은 1 이하의 양수이고, 파랗게 표시된 부분은 이전의 분산이다.

따라서, 새로운 데이터 $y_{t+1}$ 를 이용하여 추정을 하면 이전보다 분산이 작아진다는 것을 확인할 수 있고, 이는 확신도가 증가한다는 것을 의미한다.

만일 $\mathbb{E} [\varepsilon^2_y]$ 가 크면 그 감소폭이 작아진다. vise versa.

#### Time update: $\mu_{t+1 | t}$

그럼, 시간이 흐름에 따라 추정하는 경우를 생각해보자. 즉, 이번에는 새로운 데이터 $y_{t+1}$를 이용하여 추정하는 것이 아닌, 기존 $t$ 시점의 추정값을 이용하여 $t+1$ 시점을 추정하는 것이다. 즉, 시간이 지남에 따라 자연스럽게 도출되는 결과라고 생각하면 된다.

conditional mean은 다음과 같다.

$$
\begin{align*}
\mu_{t+1 | t} &= \mathbb{E}[\alpha x_t + \beta + \varepsilon_x | t] \\
&= \alpha \mu_{t | t} + \beta
\end{align*}
$$

즉, 이전 mean을 update한 것이다. 직관적이다.

#### Time update: $\sigma^2_{t+1 | t}$

conditional covariance는 다음과 같다.

$$
\begin{align*}
\sigma^2_{t+1|t} &= \mathbb{E}[x_{t+1}^2 | t ] - \mathbb{E}[x_{t+1}|t]^2 \\
&= \mathbb{E}[(\alpha x_t + \beta + \varepsilon_x)^2 | t] - \mathbb{E}[\alpha x_t + \beta + \varepsilon_x | t]^2 \\
&= \alpha^2 \sigma^{2}_{t | t} + \mathbb{E}[\varepsilon_x^2]
\end{align*}
$$

이는 observation update와는 다르게, variance를 **증가**시키는 term $\mathbb{E}[\varepsilon^2_x]$이 있음을 알 수 있다. 

직관적으로 생각하면, 시간이 지날수록 이전 추정값에 대한 신뢰도가 낮아진다고 생각할 수 있다.

### 그래서?

결국 이 time update와 observation update를 반복하면 임의의 시점에서의 위치를 추정할 수 있고, 그 정확도는 점점 높아진다는 것을 확인할 수 있다. 또한, 각 update는 $O(1)$ 이므로, 아주 쉽게 수행할 수 있다!

이렇게 아폴로 미션은 성공할 수 있었다. 하지만, 사실 위치를 아는 것 만으로는 부족하다. 정확히는 현재 위치와 속도를 알아야 미래의 운동을 예측할 수 있기 때문이다. 따라서, 현실적으로는 위치와 속도를 묶어서 하나의 벡터(혹은 행렬)로 생각하여 kalman filter를 적용한다.

이에 대해서는 다음에 알아보자!
