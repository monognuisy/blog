---
title: Linear Regression (3) - Bayesianì˜ Prediction
date: "2023-05-31"
description: "Linear regressionì˜ Prediction ë¶€ë¶„ì„ Bayesianì˜ ê´€ì ì—ì„œ í•´ì„í•˜ì"
tags: ["Machine Learning"]
categories: "AI"
---

## ì§€ë‚œ ì´ì•¼ê¸°

$$
p({\bf w} | {\cal D}) = {\cal N} ({\bf w}; {\bm \mu }_{\bf w}, \Sigma_{\bf w})
$$

where
$$
\begin{align*}
{\bm \mu}_{\bf w} &= \left(\sum_i {\bf x}_i {\bf x}_i^\top + \frac{\sigma^2}{\sigma^2_0} {\bf I} \right) ^{-1} \sum_i y_i{\bf x}_i\\\\
\Sigma_{\bf w} &= \sigma^2\left( \sum_i {\bf x}_i {\bf x}_i^\top + \frac{\sigma^2}{\sigma^2_0} {\bf I}\right)^{-1}
\end{align*}
$$

## Prediction

### ë“¤ì–´ê°€ê¸° ì•ì„œ

ë³µì¡í•œ ìˆ˜ì‹ì´ ë§ì´ ë“±ì¥í•  ì˜ˆì •. ë”°ë¼ì„œ, **ëª¨ë°”ì¼ë³´ë‹¤ëŠ” PCì—ì„œ ë³´ëŠ” ê²ƒì´ ì •ì‹ ì ìœ¼ë¡œë„ ì‹ ì²´ì ìœ¼ë¡œë„ í›¨ì”¬ ì¢‹ìŠµë‹ˆë‹¤**.

ë˜í•œ, ì´ë¥¼ ì˜ ì´í•´í•˜ê¸° ìœ„í•´ì„œëŠ” **ì„ í˜•ëŒ€ìˆ˜í•™**, **ë‹¤ë³€ìˆ˜ ì •ê·œë¶„í¬**, **ë² ì´ì¦ˆ ì •ë¦¬**ì— ëŒ€í•œ ì´í•´ê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

### Predictive Distribution

Trainingì„ ë§ˆì³¤ìœ¼ë¯€ë¡œ Predictionì„ í•  ì°¨ë¡€ë‹¤. Bayesianì€ í•˜ë‚˜ì˜ pointë¡œ ë‹µì„ ë‚´ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì¼ì¢…ì˜ densityë¡œ ë‹µì„ ë‚¸ë‹¤.

ìƒˆë¡œìš´ input ${\bf x}$ ì™€ ê·¸ë¡œ ê¸°ëŒ€ë˜ëŠ” output $y$ ë¥¼ ë„ì…í•˜ì. ê·¸ëŸ¬ë©´, ê¸°ì¡´ì˜ data $\cal D$ ì™€ ${\bf x}$ì— ëŒ€í•œ $y$ ì˜ **predictive density**ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
p(y | {\bf x}, {\cal D}) = \int _{{\bf w} \in {\cal W} } p(y | {\bf x}, {\bf w}) p({\bf w} | {\cal D})~{\rm d} {\bf w}
$$

ì¦‰, ìƒˆë¡œìš´ ${\bf x}, y$ ì— ëŒ€í•œ likelihoodì— ì§€ê¸ˆê¹Œì§€ ëª¨ì•˜ë˜ ì •ë³´ì¸ posteriorì„ ê³±í•´ì„œ ëª¨ë“  ${\bf w}$ì— ëŒ€í•´ ì ë¶„í•œ ê²ƒì´ë‹¤.

ì´ë ‡ê²Œ ë˜ë©´, í›Œë¥­í•œ ${\bf w}$ ë“¤ì— ê¸°ë°˜í•œ likelihoodë§Œ ë‚¨ê²Œ ëœë‹¤.

ì´ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´, ì •ì ë¶„ ë‚´ì˜ ì‹ë§Œ ì „ê°œí•´ë³´ì.

#### ì •ì ë¶„ ë‚´ì˜ ì‹

ê·¸ ì „ì—, ë‘˜ ë‹¤ gaussian ì´ë¯€ë¡œ, ê²°ê³¼ì ìœ¼ë¡œ ë˜ ë‹¤ë¥¸ gaussianì´ ë  ê²ƒì´ë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.

ë˜í•œ, ì–´ì°¨í”¼ ${\bf w}$ ì— ëŒ€í•´ ì •ì ë¶„í•  ê²ƒì´ë¯€ë¡œ ${\bf w}$ ì— ëŒ€í•´ ì •ë¦¬í•´ì•¼ í•¨ê³¼, ${\bf w}$ëŠ” ê³§ ì—†ì–´ì§ˆ ë³€ìˆ˜ë¼ëŠ” ê²ƒë„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  predictive densityëŠ” $y$ì— ëŒ€í•œ density ì´ë¯€ë¡œ, $y$ ì— ëŒ€í•´ì„œë„ ì •ë¦¬í•´ì•¼ í•œë‹¤.

í•´ì•¼ í•  ê²ƒì´ ë§ì€ë°, ì²œì²œíˆ ì§€ê¸ˆê» í•´ì™”ë˜ ê²ƒê³¼ ê°™ì€ ë°©ë²•ìœ¼ë¡œ í•´ë³´ì.

ë‘ê°œì˜ gaussianì´ ê³±í•´ì§„ ê¼´ì´ë¯€ë¡œ, $\exp$ ë‚´ë¶€ì˜ í•­ë§Œ ì¨ë³´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\begin{equation}
-\frac{1}{2\sigma^2} (y - {\bf w}^\top {\bf x})^2 - \frac{1}{2\sigma^2}({\bf w} - {\bm \mu}_{\bf w})^\top \sigma^2 \Sigma_{\bf w}^{-1} ({\bf w} - {\bm \mu}_{\bf w})
\end{equation}
$$

ì—¬ê¸°ì„œ, ë‹¤ìŒì„ ì´ìš©í•˜ë©´ [ì‹ 1]ì„ ì¡°ê¸ˆ ê°„ë‹¨íˆ í•  ìˆ˜ ìˆë‹¤.

$$
\Sigma^{-1}_{\bf w}{\bm \mu}_{\bf w} = \frac{1}{\sigma^2}\sum_{i} y_i {\bf x}_i
$$

$$
\begin{equation}
\begin{align*}
-\frac{1}{2\sigma^2} \left\{ y^2 - 2y{\bf w}^\top {\bf x} + ({\bf w}^\top {\bf x})^2 +
{\bf w}^\top \left(\sum_{i} {\bf x}_i{\bf x}_i^\top + \frac{\sigma^2}{\sigma^2_0}I  \right) {\bf w}
-2{\bf w}^\top \sum_{i}y_i {\bf x}_i
\right\}
\end{align*}
\end{equation}
$$

ë¨¼ì € [ì‹ 2]ì—ì„œ ${\bf w}$ì— ëŒ€í•œ ì´ì°¨í˜•ì‹ì„ ë½‘ì•„ë‚´ì. ì¼ë‹¨, ì•ì˜ $-1/2\sigma^2$ ì€ ì§€ë©´ìƒ ì ê¹ ì“°ì§€ ì•Šê² ë‹¤.

ë˜í•œ, $\sum_i {\bf x}_i {\bf x}_i^\top = XX^\top$, $\sum_i y_i{\bf x}_i = X{\bf y}$ ë¡œ ì“°ì.
([Linear Regression (1) - Frequentist](/ai/linreq-freq) ì°¸ê³ )

$$
{\bf w}^\top \left( {\bf x}{\bf x}^\top + XX^\top + \frac{\sigma^2}{\sigma^2_0}I \right){\bf w} - 2{\bf w}^\top \left(y{\bf x} + X{\bf y} \right) + y^2
$$

[Linear Regression (2) - Bayesianì˜ Training](/ai/linreg-bayes-1) ì˜ ì™„ì „ì œê³±ì‹ ê³µì‹ì„ ì°¸ê³ í•˜ë©´, ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬ëœë‹¤.

$$
\begin{equation}
\underbrace{({\bf w} - ğŸ˜Š)^\top ğŸ‘¹ ({\bf w} - ğŸ˜Š)}_{{}\text{quadratic form of }{\bf w}}  + y^2 - ğŸ˜Š^\topğŸ‘¹ğŸ˜Š
\end{equation}
$$

ë‹¨, ì—¬ê¸°ì„œ $ğŸ˜Š$ì™€ $ğŸ‘¹$ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\begin{align*}
ğŸ˜Š &= \left({\bf x}{\bf x}^\top + XX^\top + \frac{\sigma^2}{\sigma^2_0}I\right)^{-1}(y{\bf x} + X{\bf y})
\\\\
ğŸ‘¹ &= {\bf x}{\bf x}^\top + XX^\top + \frac{\sigma^2}{\sigma^2_0}I
\end{align*}
$$

ì´ë•Œ [ì‹ 3]ì—ì„œ ${\bf w}$ì— ëŒ€í•œ ì´ì°¨í˜•ì‹ì€ ì ë¶„í•˜ë©´ ìƒìˆ˜ê°€ ë˜ë¯€ë¡œ, ë’¤ì˜ í•­ë§Œ ë‚¨ê²Œ ëœë‹¤.

ë’¤ì˜ í•­ì„ ì „ê°œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
y^2  - (y{\bf x} + X{\bf y})^\top \left( {\bf x}{\bf x}^\top +XX^\top + \frac{\sigma^2}{\sigma_0^2} I \right)^{-1} (y{\bf x} + X{\bf y})
$$

ì´ ë˜í•œ ì´ì°¨ì‹ì´ë¯€ë¡œ, ì™„ì „ì œê³±ì‹ìœ¼ë¡œ ë°”ê¿€ ìˆ˜ ìˆë‹¤. ì‚´ì§ ì „ê°œí•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
y^2 \left( 1 - {\bf x}^\top \left( {\bf x}{\bf x}^\top + XX^\top+ \frac{\sigma^2}{\sigma^2_0}I \right) {\bf x}\right) - 2y{\bf x}^\top \left( {\bf x}{\bf x}^\top + XX^\top+ \frac{\sigma^2}{\sigma^2_0}I \right)X{\bf y} + \cdots
$$

ì—¬ê¸°ì— ì›ë˜ ë¶™ì–´ìˆë˜ $-1/2\sigma^2$ ë¥¼ ê³±í•˜ê³ , ì´ë¥¼ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ ì™„ì „ì œê³±ì‹ì´ ë‚˜ì˜¨ë‹¤.

$$
-\frac{(y - ğŸ‰)^2}{2 ğŸ¦„}
$$

Gaussian!

ë‹¨, ì—¬ê¸°ì„œ $ğŸ‰$ì™€ $ğŸ¦„$ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\begin{align*}
ğŸ‰ &= \frac{{\bf x}^\top ( {\bf x}{\bf x}^\top + XX^\top + \frac{\sigma^2}{\sigma^2_0}I) ^{-1} X{\bf y}}{1 - {\bf x}^\top ({\bf x}{\bf x}^\top + XX^\top + \frac{\sigma^2}{\sigma^2_0}I)^{-1} {\bf x}}
\\\\
ğŸ¦„ &= \frac{\sigma^2}{1 - {\bf x}^\top ({\bf x}{\bf x}^\top + XX^\top + \frac{\sigma^2}{\sigma^2_0}I)^{-1} {\bf x}}
\end{align*}
$$

ê·¸ë¦¬ê³ , ì´ëŠ” $p(y | {\bf x}, {\cal D})$ ì˜ í‰ê· ($ğŸ‰$)ê³¼ ë¶„ì‚°($ğŸ¦„$)ì´ë‹¤!

### ë‹¤ì‹œ ëŒì•„ì˜¨ ë¶„ì„ íƒ€ì„

í â€¦ ë¶„ì„ì„ í•´ì•¼ í•˜ëŠ”ë°, ì‚¬ì‹¤ ì‹ì´ ë„ˆë¬´ ë”ëŸ½ë‹¤ ã…ã…. ê·¸ë˜ì„œ, ì§€ê¸ˆ ë§ì€ ë¶„ì„ì„ í•˜ê¸°ëŠ” í˜ë“¤ê³ , ë‹¤ë¥¸ ì„ í˜•ëŒ€ìˆ˜í•™ì  toolë“¤ì„ ì´ìš©í•˜ì—¬ ì‹ì„ ì¡°ê¸ˆ ì •ë¦¬í•œ ë’¤ì— ë¶„ì„ì„ í•´ë³´ê³ ì í•œë‹¤.

ê·¸ë˜ë„, ì§€ê¸ˆ ì•Œ ìˆ˜ ìˆëŠ” ê²ƒì€ ë¶„ì‚° ${\rm Var}[y | {\bf x} , \cal D]$ =$ğŸ¦„$ì´ í•­ìƒ $\sigma^2$ ì´ìƒì´ë¼ëŠ” ê²ƒì´ë‹¤.

(ì™œëƒí•˜ë©´, ë¶„ëª¨ê°€ í•­ìƒ $0$ ì´ìƒ $1$ ì´í•˜ì´ë¯€ë¡œ!)

ì¦‰, ì´ëŠ” ìš°ë¦¬ê°€ ì•„ë¬´ë¦¬ predictionì„ ì˜ í•´ë„ ì›ë˜ modelì˜ error(noise)ì¸ $\sigma^2$ ë¯¸ë§Œìœ¼ë¡œì˜ ë¶ˆí™•ì‹¤ë„ë¡œëŠ” predictioní•  ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì´ë‹¤.

ì´ëŠ” ì–´ì°Œë³´ë©´ ìëª…í•˜ë‹¤. ì›ë˜ì˜ densityë³´ë‹¤ë„ ë”ìš± ë¶„ì‚°ì´ ì ê²Œ ì˜ˆì¸¡í•˜ëŠ” ê²ƒì€ ë§ì´ ì•ˆë˜ê¸° ë•Œë¬¸ì´ë‹¤.

### ê°„ì†Œí™”!

ì§€ê¸ˆì˜ í‰ê· , ë¶„ì‚° ì‹ì€ ë„ˆë¬´ë‚˜ë„ ë³µì¡í•˜ë‹¤! íŠ¹íˆ, í‰ê· ì´ êµ‰ì¥íˆ ë³µì¡í•˜ë‹¤. ì´ë¥¼ ê°„ë‹¨í•˜ê²Œ í•˜ê¸° ìœ„í•´ì„œ ë‹¤ìŒì˜ ìœ ëª…í•œ í•­ë“±ì‹ì„ ì†Œê°œí•œë‹¤.

> **Woodbury Matrix Identity**
>
> í–‰ë ¬ $A\in \R^{D\times D},~ C \in \R^{N \times N}, ~U\in \R^{D\times N}, ~ V\in \R^{N \times D}$ ì— ëŒ€í•˜ì—¬ $A, C$ ê°€ invertible ì´ë©´ ë‹¤ìŒì´ ì„±ë¦½í•œë‹¤.
>
>
> $$
> (A + UCV)^{-1} = A^{-1} - A^{-1}U(C^{-1} + VA^{-1}U)^{-1} VA^{-1}
> $$
>

$y | {\bf x}, \cal D$ ì˜ í‰ê· ê³¼ ë¶„ì‚°ì„ ë³´ë©´, ë¶„ëª¨ê°€ ë™ì¼í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ë¨¼ì € **ë¶„ëª¨**ë¥¼ ë³´ì.

$$
\begin{equation}
1 - {\bf x}^\top \left({\bf x}{\bf x}^\top + XX^\top + \frac{\sigma^2}{\sigma^2_0}I \right)^{-1} {\bf x}
\end{equation}
$$

ì—¬ê¸°ì„œ $A^{-1} = 1$, $U = {\bf x}^\top$, $C^{-1} = XX^\top + \frac{\sigma^2}{\sigma^2_0} I$, $V = {\bf x}$ ë¼ê³  í•˜ë©´, [ì‹ 4]ëŠ” Woodbury í•­ë“±ì‹ì˜ ìš°ë³€ê³¼ ë™ì¼í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.

ë”°ë¼ì„œ, [ì‹ 4]ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë³€í˜•ëœë‹¤.

$$
\left( 1+ {\bf x} \left( XX^\top + \frac{\sigma^2}{\sigma^2_0}I \right)^{-1} {\bf x} \right)^{-1}
$$

ì—¬ê¸°ì„œ $(XX^\top + \frac{\sigma^2}{\sigma^2_0} I)^{-1}$ ì— í•­ë“±ì‹ì„ ì ìš©í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìœ¼ë¯€ë¡œ:

$$
\left(XX^\top + \frac{\sigma^2}{\sigma^2_0} I\right)^{-1} = \frac{\sigma^2_0}{\sigma^2}I - \frac{\sigma^4_0}{\sigma^4} X\left( I + \frac{\sigma^2_0}{\sigma^2}X^\top X \right)^{-1} X^\top
$$

ë¶„ëª¨ì¸ [ì‹ 4]ëŠ” ìµœì¢…ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\left(1 + \frac{\sigma^2_0}{\sigma^2} \left( {\bf x}^\top {\bf x} - {\bf x}^\top X\left( X^\top X +  \frac{\sigma^2}{\sigma^2_0} I \right)^{-1} X^\top{\bf x} \right) \right)^{-1}
$$

ì´ëŠ” ìŠ¤ì¹¼ë¼ì´ë¯€ë¡œ, ê²°êµ­ inverseëŠ” ì—­ìˆ˜ì™€ ë™ì¼í•˜ë‹¤.

ì¦‰, **ë¶„ì‚°**ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\begin{align*}
{\rm Var}[y | {\bf x}, {\cal D}] &= \sigma^{2} \left(1 + \frac{\sigma^2_0}{\sigma^2} \left( {\bf x}^\top {\bf x} - {\bf x}^\top X\left( X^\top X +  \frac{\sigma^2}{\sigma^2_0} I \right)^{-1} X^\top{\bf x} \right) \right)\\\\
&=\color{crimson}{\sigma^2} \color{black}{+} \color{cornflowerblue}{ \sigma^2_0{\bf x}^\top {\bf x} - \sigma^2_0 {\bf x}^\top X \left( X^\top X + \frac{\sigma^2}{\sigma^2_0} I \right)^{-1} X^\top {\bf x}}

\end{align*}
$$

### ë‹¤ì‹œ ëŒì•„ì˜¨ ë¶„ì„ íƒ€ì„

ì—¬ê¸°ì„œ <Highlight color='red'>**ë¹¨ê°„ìƒ‰ term**</Highlight>ê³¼
<Highlight color='blue'>**íŒŒë€ìƒ‰ term**</Highlight>ì˜ í•©ìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤ëŠ” ì ì— ì£¼ëª©í•˜ì.

<Highlight color='red'>**ë¹¨ê°„ìƒ‰ term**</Highlight>ì„
**Aleatoric uncertainty**ë¼ê³  í•˜ë©°, ì´ëŠ” underline density functionì˜ uncertaintyë¥¼ ì˜ë¯¸í•œë‹¤.

<Highlight color='blue'>**íŒŒë€ìƒ‰ term**</Highlight>ì€
**Episdemic uncertainty**ë¼ê³  í•˜ë©°, ì´ëŠ” data ìˆ˜ì— ë”°ë¥¸ uncertaintyë¥¼ ì˜ë¯¸í•œë‹¤.

ì•ì„œ ë³´ì•˜ë“¯ì´, Aleatoric uncertainty ë³´ë‹¤ ì‘ê²Œ ë¶„ì‚°ì„ ë§Œë“¤ìˆ˜ëŠ” ì—†ë‹¤. (ì§ì ‘ Episdemic uncertainty $\ge 0$ ì„ì„ í™•ì¸í•´ë³´ë¼!) ë§Œì¼, Episdemic uncertaintyê°€ $0$ ì´ë¼ë©´, ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì´ë‹¤.

$$
X \left( X^\top X + \frac{\sigma^2}{\sigma^2_0} I \right)^{-1} X = I
$$

ì¦‰, [Linear Regression (2) - Bayesianì˜ Training](/ai/linreg-bayes-1) ì—ì„œ ê´€ì°°í•œ posterior ì˜ ë¶„ì‚°ê³¼ ë¹„ìŠ·í•˜ê²Œ $N \to \infty$ ì¸ ê²½ìš°ë¥¼ ì˜ë¯¸í•˜ëŠ” ê²ƒì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.

ì¢‹ë‹¤. ì´ë ‡ê²Œ í‰ê· ë„ ê°„ì†Œí™”ì‹œì¼œë³´ì.

### í‰ê· ì˜ ê°„ì†Œí™”

ë¶„ëª¨ëŠ” ì´ë¯¸ ê°„ì†Œí™” ì‹œì¼°ìœ¼ë‹ˆ, **ë¶„ì**ë¥¼ ê°„ì†Œí™” í• ë•Œì´ë‹¤. ë¶„ìëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\begin{equation}
{\bf x} \left( {\bf x}{\bf x}^\top + XX^\top \frac{}{} + \frac{\sigma^2}{\sigma^2_0}I \right)^{-1} X{\bf y}
\end{equation}
$$

ì¤‘ê°„ì˜ inverseë¥¼ Woodbury identityë¥¼ ì´ìš©í•˜ì—¬ ì „ê°œí•˜ì. $A = XX^\top + \frac{\sigma^2}{\sigma^2_0} I$ , $U = {\bf x}$, $V = {\bf x}^\top$, $C = 1$  ì´ë¼ê³  í•˜ì.

í•­ë“±ì‹ì˜ $(C^{-1} + VA^{-1}U)^{-1}$ ë¶€ë¶„ì€ ìŠ¤ì¹¼ë¼ê¸° ë•Œë¬¸ì—, ê°„ë‹¨íˆ ì—­ìˆ˜ë¡œ í‘œí˜„í•˜ë©´ [ì‹ 5]ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
{\bf x}^\top \left( XX^\top + \cfrac{\sigma^2}{\sigma^2_0}I \right)^{-1} X{\bf y} - \cfrac{{\bf x}^\top \left( XX^\top + \cfrac{\sigma^2}{\sigma^2_0}I \right)^{-1}{\bf x} {\bf x}^\top \left( XX^\top + \cfrac{\sigma^2}{\sigma^2_0}I \right)^{-1} X{\bf y} }{1 + {\bf x}^\top {\left( XX^\top + \cfrac{\sigma^2}{\sigma^2_0}I \right)^{-1}} {\bf x}}
$$

ì´ë¥¼ í†µë¶„(ã„·ã„·)í•˜ì—¬ ê³„ì‚°í•˜ë©´, ë’· í•­ì˜ ìƒë‹¹íˆ ê¸´ ë¶„ì ë¶€ë¶„ì´ ì‚¬ë¼ì§„ë‹¤. ê·¸ëŸ¬ë©´ [ì‹ 5]ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\cfrac{{\bf x}^\top \left( XX^\top + \cfrac{\sigma^2}{\sigma^2_0}I \right)^{-1} X{\bf y}}{1 + {\bf x}^\top {\left( XX^\top + \cfrac{\sigma^2}{\sigma^2_0}I \right)^{-1}} {\bf x}}
$$

ì—¬ê¸°ì„œ $(XX^\top + \frac{\sigma^2}{\sigma^2_0} I)^{-1}$ ì— í•­ë“±ì‹ì„ ì ìš©í•˜ë©´:

$$
\begin{equation}
\cfrac{\cfrac{\sigma^2_0}{\sigma^2} \left( {\bf x}^\top X{\bf y} - {\bf x}^\top X\left( X^\top X +  \cfrac{\sigma^2}{\sigma^2_0} I \right)^{-1} X^\top X{\bf y} \right)}{ 1 + \cfrac{\sigma^2_0}{\sigma^2} \left( {\bf x}^\top {\bf x} - {\bf x}^\top X\left( X^\top X +  \cfrac{\sigma^2}{\sigma^2_0} I \right)^{-1} X^\top{\bf x} \right)}
\end{equation}
$$

í‰ê·  = ë¶„ì / ë¶„ëª¨ ì´ë¯€ë¡œ, ë¶„ìì— ë¶„ëª¨ì˜ ì—­ìˆ˜ë¥¼ ê³±í•˜ë©´ í‰ê· ì„ ë„ì¶œí•  ìˆ˜ ìˆë‹¤.

ì—¬ê¸°ì„œ, ì›ë˜ì˜ ë¶„ëª¨ì˜ ì—­ìˆ˜ëŠ” [ì‹ 6]ì˜ ë¶„ëª¨ì™€ ê°™ìœ¼ë¯€ë¡œ, ì„œë¡œ ì†Œê±°ëœë‹¤.

ì¦‰, í‰ê· ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\begin{align*}
{\mathbb{E}} [y | {\bf x}, {\cal D}] &= \frac{\sigma^2_0}{\sigma^2} \left( {\bf x}^\top X{\bf y} - {\bf x}^\top X\left( X^\top X +  \frac{\sigma^2}{\sigma^2_0} I \right)^{-1} X^\top X{\bf y} \right) \\
&= \frac{\sigma^2_0}{\sigma^2} \left( {\bf x}^\top - {\bf x}^\top X\left( X^\top X +  \frac{\sigma^2}{\sigma^2_0} I \right)^{-1} X^\top  \right)X{\bf y} \\
&= \frac{\sigma^2_0}{\sigma^2} {\bf x}^\top \left( I - X\left( X^\top X +  \frac{\sigma^2}{\sigma^2_0} I \right)^{-1} X^\top  \right)X{\bf y}
\end{align*}
$$

ë§ˆì§€ë§‰ ì‹ì˜ ${\bf x}^\top$ ì„ **query point**ë¼ê³  ë¶€ë¥¸ë‹¤.

### ì¡°ê¸ˆë§Œ, ì¡°ê¸ˆë§Œ ë”

ì•½ê°„ë§Œ ë” ê°„ì†Œí™”í•´ë³´ì. Woodbury identityë¥¼ ê³„ì† ì´ìš©í•˜ë©´ ëœë‹¤.

$A^{-1} = I$, $U = X$, $V = X^\top$, $C^{-1} = \frac{\sigma^2}{\sigma^2_0}I$ ë¼ê³  í•˜ë©´, í‰ê· ì€ ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬ë  ìˆ˜ ìˆë‹¤.

$$
\begin{align*}
{\mathbb{E}} [y | {\bf x}, {\cal D}] &= \frac{\sigma^2_0}{\sigma^2} {\bf x}^\top \left( I + \frac{\sigma^2_0}{\sigma^2}X X^\top   \right)^{-1} X{\bf y} \\
&= {\bf x}^\top \left( XX^\top + \frac{\sigma^2}{\sigma^2_0}I \right)^{-1} X{\bf y}
\end{align*}
$$

### ë‹¤.ëŒ.ë¶„.íƒ€.

ì•—! ì–´ë””ì„œ ë§ì´ ë³¸ ì‹ì´ ë“±ì¥í–ˆë‹¤!

$$
\begin{equation}
{\bf x}^\top \left( XX^\top + \frac{\sigma^2}{\sigma^2_0}I \right)^{-1} X{\bf y}
\end{equation}
$$

ì˜¤! ì´ê²ƒì€ Frequentistë“¤ì´ regularization termì„ í¬í•¨ì‹œì¼œì„œ ê³„ì‚°í•œ linear regressionì˜ predictionê³¼ë„ ì°¸ ë‹®ì•˜ë‹¤. ë˜í•œ,
[Linear Regression (2) - Bayesianì˜ Training](/ai/linreg-bayes-1) ì—ì„œì˜ $\bm \mu_{\bf w}$ ë¥¼ ì´ìš©í•˜ì—¬ prediction í•œ ê²ƒìœ¼ë¡œë„ ìƒê°í•  ìˆ˜ ìˆë‹¤.

ì§ê´€ì ìœ¼ë¡œ ìƒê°í•˜ë©´, $y | {\bf x}, \cal D$ ì˜ í‰ê· ì€ ê°€ì¥ densityê°€ ë†’ì€ ê°’ì´ë¯€ë¡œ, ê°€ì¥ ê·¸ëŸ´ì‹¸í•œ predictionì„ ì˜ë¯¸í•˜ê³ , ì´ëŠ” ê°€ì¥ ê·¸ëŸ´ì‹¸í•œ $\bm \mu_{\bf w}$ë¥¼ ì´ìš©í•˜ì—¬ predictioní•œ ê²ƒê³¼ ê°™ë‹¤.

ê²°êµ­, Frequentistì™€ Bayesianì´ ë˜ë‹¤ì‹œ ë§Œë‚¬ë‹¤!

ë¬¼ë¡ , ì—¬ê¸°ì„œë„ $N$ì„ í¬í•¨ì‹œì¼œì„œ $N$ì˜ ë³€í™”ì— ë”°ë¥¸ ì§€ë°°ì ì¸ termì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

### ì—¬ê¸°ì„œ ë”?

[ì‹ 7]ì„ ì¡°ê¸ˆ ë” ë³€í˜•ì‹œì¼œì„œ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ ë„ì¶œí•  ìˆ˜ë„ ìˆë‹¤. ë‹¤ìŒê³¼ ê°™ì´ $X$ë¥¼ ì•ìœ¼ë¡œ ëº„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,

$$
\left( XX^\top + \frac{\sigma^2}{\sigma^2_0} \right)X = X \left( X^\top X + \frac{\sigma^2}{\sigma^2_0} \right)
$$

ì•ì— $(XX^\top + \frac{\sigma^2}{\sigma^2_0})^{-1}$, ë’¤ì— $(X^\top X + \frac{\sigma^2}{\sigma^2_0})^{-1}$ ì„ ê³±í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
X \left( X^\top X + \frac{\sigma^2}{\sigma^2_0} \right)^{-1} = \left( XX^\top + \frac{\sigma^2}{\sigma^2_0} \right)^{-1} X
$$

ì´ë¥¼ [ì‹ 7]ì— plugin í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
[ì‹ ~ 7] = {\bf x}^\top X \left(X^\top X + \frac{\sigma^2}{\sigma^2_0}I \right)^{-1} {\bf y}
$$

ì´ë•Œ, $\gamma = \frac{\sigma^2}{\sigma^2_0}$  ì´ë¼ê³  í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì“¸ ìˆ˜ ìˆë‹¤.

$$
{\bf x}^\top X(X^\top X + \gamma I)^{-1} {\bf y}
$$

ì´ì˜ ì˜ë¯¸ëŠ” í›„ì— Gaussian Process ë¥¼ ë‹¤ë£°ë•Œ ì•Œê²Œ ë  ê²ƒì´ë‹¤.

<details>
inverse termì„ ë‹¤ì‹œ í•­ë“±ì‹ì„ ì´ìš©í•˜ì—¬ ì „ê°œí•˜ê³ , ë’¤ì˜ $X$ë¥¼ ê³±í•œ ë’¤, ì•ìœ¼ë¡œ êº¼ë‚´ì.

$$
\begin{align*}
[ì‹~7] &= {\bf x}^\top \left(\frac{\sigma^2_0}{\sigma^2}I - \frac{\sigma^4_0}{\sigma^4}X \left( I + \frac{\sigma^2_0}{\sigma^2} X^\top X \right)^{-1} X^\top  \right)X{\bf y} \\
&= {\bf x}^\top X \left(\frac{\sigma^2_0}{\sigma^2}I - \frac{\sigma^4_0}{\sigma^4} \left( I + \frac{\sigma^2_0}{\sigma^2} X^\top X \right)^{-1} X^\top X  \right){\bf y}
\end{align*}
$$

ì—¬ê¸°ì„œ $A^{-1} = \frac{\sigma^2_0}{\sigma^2} I$, $U=  I \in \R^{N \times N}$, $V = X^\top X$, $C^{-1} = I$ ë¼ê³  í•˜ë©´ ëœë‹¤.
</details>
