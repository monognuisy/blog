{"componentChunkName":"component---src-templates-blog-post-tsx-content-file-path-users-sungminyoo-desktop-personal-blog-content-blog-ai-bayesian-linreg-bayes-2-mdx","path":"/ai-bayesian/linreg-bayes-2/","result":{"data":{"site":{"siteMetadata":{"title":"monognuisy blog."}},"mdx":{"id":"5f50cf8e-5fb8-51a8-ab42-c74728ceacca","excerpt":"지난 이야기 p(w∣D)=N(w;μw,Σw)p({\\bf w} | {\\cal D}) = {\\cal N} ({\\bf w}; {\\bm \\mu }_{\\bf w}, \\Sigma_{\\bf w})p(w∣D)=N(w;μw​,Σw​)\n\nwhere\n\nμw=(∑ixixi⊤+σ2σ02I)−1∑iyixiΣw=σ…","tableOfContents":{"items":[{"url":"#지난-이야기","title":"지난 이야기"},{"url":"#prediction","title":"Prediction","items":[{"url":"#들어가기-앞서","title":"들어가기 앞서"},{"url":"#predictive-distribution","title":"Predictive Distribution","items":[{"url":"#정적분-내의-식","title":"정적분 내의 식"}]},{"url":"#다시-돌아온-분석-타임","title":"다시 돌아온 분석 타임"},{"url":"#간소화","title":"간소화!"},{"url":"#다시-돌아온-분석-타임-1","title":"다시 돌아온 분석 타임"},{"url":"#평균의-간소화","title":"평균의 간소화"},{"url":"#조금만-조금만-더","title":"조금만, 조금만 더"},{"url":"#다돌분타","title":"다.돌.분.타."},{"url":"#여기서-더","title":"여기서 더?"}]}]},"frontmatter":{"title":"Linear Regression (3) - Bayesian의 Prediction","date":"May 31, 2023","description":"Linear regression의 Prediction 부분을 Bayesian의 관점에서 해석하자","tags":["AI","Mathematics"],"sidenotes":null}},"previous":{"fields":{"slug":"/functional/sml2-tuplelist/"},"frontmatter":{"title":"SML - 유용한 자료구조"}},"next":{"fields":{"slug":"/ai-bayesian/d-separation/"},"frontmatter":{"title":"Graphical Models & D-separation"}}},"pageContext":{"id":"5f50cf8e-5fb8-51a8-ab42-c74728ceacca","previousPostId":"551bfcd0-cee1-521b-82fd-3e14647f4ddc","nextPostId":"a1411eca-9248-54ee-8a66-0a7241a0c49c","frontmatter":{"title":"Linear Regression (3) - Bayesian의 Prediction","date":"2023-05-31","description":"Linear regression의 Prediction 부분을 Bayesian의 관점에서 해석하자","tags":["AI","Mathematics"],"categories":"AI - Bayesian Approach"}}},"staticQueryHashes":["2841359383","3274528899"],"slicesMap":{}}